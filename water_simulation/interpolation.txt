https://www.netlib.org/fdlibm/
Math library implementation

Remez algorithm
- https://sites.tufts.edu/atasissa/files/2019/09/remez.pdf - the article doesn't provide the python code mentioned (at least I could find it anywhere).
- https://en.wikipedia.org/wiki/Remez_algorithm
- https://en.wikipedia.org/wiki/Approximation_theory

The goal of the algorithm is to find the polynomial with the smallest maximum difference from some function. The sufficient and nescesarry condition for such a polynomial of degree n given by the equioscillation theorem is that there are n + 2 maxima or minima where the maximum error or negated maxium error is achived. The Ramez algorithm works by enforcing the error p(x) - f(x) oscilates back and forth n + 2 times achiveing a value E (the value isn't nescessarily achived at the extrema) by constructing a system of linear equations. Then the nodes are interatively modified so the maximum error is achieved at the extrema of p(x) - f(x).

The minimax polynomial might not give the best result using a given machine precision. More about that: https://stackoverflow.com/questions/26692859/best-machine-optimized-polynomial-minimax-approximation-to-arctangent-on-1-1

Also alternatively istead of minimizing the absolute error then relative error can be minimized. To do this x_i^k in the linear system has to be replaced by x_i^k / f(x_i).
This is described here https://www.studies.nawaz.org/posts/remezs-algorithm/ and also it can be seen in the desmos linked here: https://math.stackexchange.com/questions/3619158/most-efficient-way-to-calculate-logarithm-numerically.

When minizing the error term of the interpolating polynomial the only part of the error term you have control over is the product of (x - x_i).
The Chebyshev nodes minimize this error in the L_infty norm.
https://en.wikipedia.org/wiki/Chebyshev_nodes

exp:
the fdlibm implementation approximates an symmetric function using which you can approximate exp, because the function is symmetric the function can then be approximated using an even polynomial, which means that you the region on which the polynomial has to be minimized is halved. I am guessing that they used an even degree vandermore matrix in the ramez algorithm to find the approximation.


Calculating exp to arbitrary precision. You could convert it into a root finding problem
for example to calculate 3^(23/7) which could be coverted into 3^3 * 3^(2/7) = 3^3 * 3^(1/7)^2

integer to float conversion
https://blog.m-ou.se/floats/

float to integer coversion
Could probably just multiply the mantissa and shift by the exponent and get rid of all the bits that are fraction bits.